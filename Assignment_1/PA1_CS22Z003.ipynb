{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " PA1 CS22Z003.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOn/hnbJjQlkfw/Th+kPy2E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akansh12/Deep-Learning-for-imaging-EE5179/blob/main/Assignment_1/PA1_CS22Z003.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Classification using MLP\n"
      ],
      "metadata": {
        "id": "q-Acap1SgWyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By \n",
        "- Akansh Maurya (CS22Z003)"
      ],
      "metadata": {
        "id": "2RgCHb3Ui82c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tasks to to:\n",
        "- Baseline: IP-h(500)-h(250)-h(100)-OP\n",
        "- Activation functions for hidden layers: Sigmoid and for the Output layer it is softmax\n",
        "- Gradient-Descent\n",
        "- lr = 0.01, batch size = 64, epoch = 15\n",
        "-  Extra marks for experimentations\n",
        "- Glorot Initialization\n",
        "- Plot the loss for 200 iterations\n",
        "- Confustion matrix and classification report\n",
        "1.1\n",
        "- Use Tanh and RELU\n",
        "\n",
        "Task 2:\n",
        "- Use pytorch for the same\n",
        "- Add L2 Regularization to it."
      ],
      "metadata": {
        "id": "bi2x5f2qgSUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Imports"
      ],
      "metadata": {
        "id": "rSZ1i9nPjYDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import keras\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from  matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "CNpq2VWIjdBS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the Dataset"
      ],
      "metadata": {
        "id": "MtymctNZjUlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source: https://keras.io/api/datasets/mnist/\n",
        "tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuSuNiYjgTBx",
        "outputId": "76252a2c-e02e-4f68-94f4-7e67679ea5a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping the dataset"
      ],
      "metadata": {
        "id": "ekNbyGONng-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train.reshape(x_train.shape[0], 784)).T\n",
        "x_test = np.array(x_test.reshape(x_test.shape[0], 784)).T\n",
        "x_train = (x_train/255.0).astype(np.float32)\n",
        "x_test = (x_test/255.0).astype(np.float32)"
      ],
      "metadata": {
        "id": "Z1Rh7u8GnRBG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Dataset Shape: \", x_train.shape)\n",
        "print(\"Train Target Vector Shape: \", y_train.shape) \n",
        "print(\"Test Dataset Shape:\", x_test.shape)\n",
        "print(\"Test Target Vector Shape\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Igf2TjDSkyP6",
        "outputId": "e864943b-760c-4d94-f9c1-f8d20731f655"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Shape:  (784, 60000)\n",
            "Train Target Vector Shape:  (60000,)\n",
            "Test Dataset Shape: (784, 10000)\n",
            "Test Target Vector Shape (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(x_train[:,48].reshape(28,28))\n",
        "print(y_train[48])\n",
        "plt.figure()\n",
        "plt.imshow(x_test[:,75].reshape(28,28))\n",
        "print(y_test[75])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "g4GmV_evncOl",
        "outputId": "086b6abd-f6ce-4d6b-fc0f-80ea901a92f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mN7IXDwclnrq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IgD3VclPlnuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H1L3iDc2lnwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mjychvIElny6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UK_pmN-Vln1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP():\n",
        "  def __init__(self, epochs, num_input_nodes, hidden_layers, num_output_nodes, lr, optimizer, batch_size, activation_function = 'sigmoid', loss_type = 'cross_entropy', w_initial = 'glorot'):\n",
        "    self.epochs = epochs\n",
        "    self.lr = lr \n",
        "    self.optimizer = optimizer\n",
        "    self.optimizer.lr = self.lr      \n",
        "    self.batch_size = batch_size\n",
        "    self.num_input_nodes = num_input_nodes\n",
        "    self.hidden_layers = hidden_layers\n",
        "    self.num_output_nodes = num_output_nodes\n",
        "    self.loss_type = loss_type\n",
        "    #Activation function\n",
        "    self.activation_function = self.activation(activation_function)\n",
        "    #parameter initialization\n",
        "    self.params = self.initialization(weight_initialisation = w_initial)\n",
        "\n",
        "  def activation(self, activation_function):\n",
        "\n",
        "    if activation_function == 'sigmoid':\n",
        "      return self.sigmoid\n",
        "    if activation_function == 'tanh':\n",
        "      return self.tanh\n",
        "    if activation_function == 'ReLU':\n",
        "      return self.relu\n",
        "\n",
        "  def sigmoid(self,x, derivative = False):\n",
        "    if derivative:\n",
        "      return self.sigmoid(x)*(1-self.sigmoid(x))\n",
        "    else:\n",
        "      return 1/(1 + np.exp(-x))\n",
        "\n",
        "  def tanh(self, x, derivative = False):\n",
        "    if derivative:\n",
        "      return 1 - self.tanh(x)**2\n",
        "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "\n",
        "  def relu(self, x, derivative = False):\n",
        "    if derivative:\n",
        "      return (x>0)*1 \n",
        "    return x*(x>0)\n",
        "\n",
        "\n",
        "  def one_hot(self,y):\n",
        "    v = np.zeros((self.num_output_nodes, len(y)))\n",
        "    for i,j in enumerate(y):\n",
        "      v[j,i] = 1\n",
        "    return v\n",
        "\n",
        "  def softmax(self,x,derivative = False):\n",
        "    if derivative:\n",
        "      return self.softmax(x)*(1- self.softmax(x))\n",
        "    else:\n",
        "      return (np.exp(x)/np.sum(np.exp(x), axis = 0))\n",
        "\n",
        "  def loss(self, y_pred, y_true):\n",
        "    if self.loss_type == 'cross_entropy':\n",
        "      return -1*np.sum(np.multiply(self.one_hot(y_true), np.log(y_pred))) # To Do: Optimize this using argmax\n",
        "\n",
        "  def initialization(self, weight_initialisation = 'random'):\n",
        "    w = []\n",
        "    b = []\n",
        "\n",
        "    if weight_initialisation == 'random':\n",
        "      w.append(np.random.randn(self.hidden_layers[0],self.num_input_nodes)*0.1)\n",
        "    elif weight_initialisation == 'Xavier':\n",
        "      w.append(np.random.randn(self.hidden_layers[0],self.num_input_nodes)*np.sqrt(2/(self.num_input_nodes+self.hidden_layers[0])))\n",
        "    b.append(np.zeros((self.hidden_layers[0], 1))) \n",
        "\n",
        "    for i in range(1,len(self.hidden_layers)):\n",
        "      if weight_initialisation == 'random':\n",
        "        w.append(np.random.randn(self.hidden_layers[i],self.hidden_layers[i-1])*0.1)\n",
        "      elif weight_initialisation == 'Xavier':\n",
        "        w.append(np.random.randn(self.hidden_layers[i],self.hidden_layers[i-1])*np.sqrt(2/(self.hidden_layers[i-1]+self.hidden_layers[i])))\n",
        "      b.append(np.zeros((self.hidden_layers[i], 1)))\n",
        "\n",
        "    if weight_initialisation == 'random':\n",
        "      w.append(np.random.randn(self.num_output_nodes,self.hidden_layers[len(self.hidden_layers)-1])*0.1)\n",
        "    elif weight_initialisation == 'Xavier':\n",
        "      w.append(np.random.randn(self.num_output_nodes,self.hidden_layers[len(self.hidden_layers)-1])*np.sqrt(2/(self.hidden_layers[len(self.hidden_layers)-1] + self.num_output_nodes)))\n",
        "    b.append(np.zeros((self.num_output_nodes, 1)))\n",
        "\n",
        "    return {'w':w, 'b':b}\n",
        "\n",
        "  def compute_accuracy(self, x_test, y_test):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    out = self.feed_forward(x_test)\n",
        "    pred = np.argmax(out, axis = 0)\n",
        "    acc=accuracy_score(y_test, pred, normalize=True, sample_weight=None)\n",
        "    return np.mean(pred == y_test)*100\n",
        "\n",
        "  def feed_forward(self, x):\n",
        "    #a=wh+b\n",
        "    #h=activation function(a)\n",
        "    self.a = []\n",
        "    self.h = []\n",
        "    self.h.append(x)\n",
        "\n",
        "    for i in range(0, len(self.hidden_layers)):\n",
        "      self.a.append(np.dot(self.params['w'][i], self.h[-1])+ self.params['b'][i])\n",
        "      self.h.append(self.activation_function(self.a[i]))\n",
        "\n",
        "    self.a.append(np.dot(self.params['w'][-1],self.h[-1])+self.params['b'][-1])\n",
        "\n",
        "    y_hat = self.softmax(self.a[-1])\n",
        "    return y_hat\n",
        "\n",
        "  def back_propagation(self, y_hat, y_true):\n",
        "    self.da = [0]* len(self.a)\n",
        "    self.dh = [0]* (len(self.h)-1)\n",
        "    self.dw = [0]* len(self.params['w'])\n",
        "    self.db = [0]* len(self.params['b'])\n",
        "\n",
        "    self.da[-1] = -1*(y_true - y_hat)\n",
        "\n",
        "    for i in range(len(self.params['w'])-1, 0, -1):\n",
        "      self.dw[i] = np.dot(self.da[i], self.h[i].T) \n",
        "      self.db[i] = self.da[i]\n",
        "\n",
        "      self.dh[i-1] = np.dot(self.params['w'][i].T, self.da[i])\n",
        "      self.da[i-1] = np.multiply(self.dh[i-1], self.activation_function(self.da[i-1], derivative=True))\n",
        "    self.dw[0] = self.da[0], self.dh[0].T\n",
        "    self.db[0] = self.da[0]\n",
        "\n",
        "    return self.dw, self.db\n",
        "\n",
        "  def train(self, x_train, y_train, x_test, y_test):\n",
        "    N = x_train.shape[1]\n",
        "    n_batches = int(np.floor(N / self.batch_size))\n",
        "    train_iter_loss = []\n",
        "    test_iter_loss = []\n",
        "    train_epoch_loss = []\n",
        "    for epoch in range(0, self.epochs):\n",
        "      l = 0\n",
        "      for batch in tqdm(range(0, n_batches)):\n",
        "        x = x_train[:,batch*self.batch_size:self.batch_size+batch*self.batch_size]\n",
        "        y = y_train[batch*self.batch_size:self.batch_size+batch*self.batch_size]\n",
        "        y_hat = self.feed_forward(x)\n",
        "\n",
        "        gW, gB = self.back_propagation(y_hat,self.one_hot(y))\n",
        "        self.params = self.optimizer.update(self.params, gW,gB)\n",
        "        l += self.loss(y_hat, self.one_hot(y))\n",
        "        if batch % 200 == 0:\n",
        "          train_iter_loss.append(self.loss(self.feed_forward(x_train)),self.one_hot(y_train))\n",
        "          test_iter_loss.append(self.loss(self.feed_forward(x_test)),self.one_hot(y_test))\n",
        "\n",
        "      try:\n",
        "        x = x_train[:,-1*N%n_batches:]\n",
        "        y = y_train[-1*N%n_batches:]\n",
        "        y_hat = self.feed_forward(x)\n",
        "        gW, gB = self.back_propagation(y_hat, self.one_hot(y))\n",
        "        self.params = self.optimizer.update(self.params, gW,gB)\n",
        "        l += self.loss(y_hat, y)\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "      train_epoch_loss.append(l/N)\n",
        "      print(f\"Epoch: {epoch}, Epoch-loss: {l/N}\")\n",
        "      print(f\"Train Accuracy: {self.compute_accuracy(x_train, y_train)}\")\n",
        "      print(f\"Test Accuracy: {self.compute_accuracy(x_test, y_test)}\")\n",
        "\n",
        "    return train_iter_loss, test_iter_loss, train_epoch_loss\n",
        "    \n"
      ],
      "metadata": {
        "id": "gUB162oqqzdb"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Optimizer\n",
        "class SGD:\n",
        "  ''' Stochastic Gradient Descent '''\n",
        "  def __init__(self, lr = 0.001):\n",
        "    self.lr = lr\n",
        "      \n",
        "  def update(self, params, gW, gB):\n",
        "    W = np.array(params['w'], dtype = object)\n",
        "    B = np.array(params['b'], dtype = object)\n",
        "    print(W.shape)\n",
        "    print(np.array(gW, dtype = object).shape)\n",
        "    W = (1)*W - self.lr * np.array(gW, dtype = object)\n",
        "    B = (1)*B - self.lr * np.array(gB, dtype = object)\n",
        "\n",
        "    return {'w':W.tolist(), 'b': B.tolist()}"
      ],
      "metadata": {
        "id": "Zs1B_ta_zaV1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B5252LQ1zaY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(epochs = 5,num_input_nodes = 784, hidden_layers = [1024, 2048, 256],num_output_nodes = 10, lr = 0.001, optimizer = SGD(), batch_size= 64, w_initial = 'random', activation_function = 'sigmoid',loss_type='cross_entropy')"
      ],
      "metadata": {
        "id": "lv36qekrvPUB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,4):\n",
        "  print(model.params['w'][i].shape)\n",
        "  print(model.params['b'][i].shape)"
      ],
      "metadata": {
        "id": "QrAMKtQ6q0KB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daec8e71-2513-474e-dbe9-c5e95d374e46"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1024, 784)\n",
            "(1024, 1)\n",
            "(2048, 1024)\n",
            "(2048, 1)\n",
            "(256, 2048)\n",
            "(256, 1)\n",
            "(10, 256)\n",
            "(10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMkwo47AACIo",
        "outputId": "c3930528-3f9b-4b4e-d4b2-c8e0607da20a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 60000)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model.feed_forward(x_train[:,:16])"
      ],
      "metadata": {
        "id": "lSQVFQQE-KDu"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dw, db = model.back_propagation(y_hat, model.one_hot(y_train[:16]))"
      ],
      "metadata": {
        "id": "xJJBDszKAJtX"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = model.optimizer.update(model.params, dw,db)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "yms5Z_bBALJ5",
        "outputId": "0121a9de-3546-434f-f746-4892c6753b9a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4,)\n",
            "(4,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-ef7815e1a2e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-b49124cb3606>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, params, gW, gB)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mB\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TG9xIJRABJAD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}